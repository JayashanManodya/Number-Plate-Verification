{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayashanManodya/Number-Plate-Verification/blob/main/Number_Plate_Verification%20(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdyV9svaXez6",
        "outputId": "22aa0942-bb4d-4413-c1c8-6dbaf9d14e6c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dependencies"
      ],
      "metadata": {
        "id": "HJJbpJ4bt4io"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rBBV2HPcr1y3",
        "outputId": "33a08825-513f-4e70-bccd-52e898fb2e35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.6/88.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/sunsmarterjie/yolov12.git roboflow supervision flash-attn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "example data"
      ],
      "metadata": {
        "id": "muM1Aivct8ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://media.roboflow.com/notebooks/examples/dog.jpeg"
      ],
      "metadata": {
        "id": "ZmLG4N2Jsswc",
        "outputId": "53db30ad-d41f-4910-e67e-258aadaef297",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-24 16:15:36--  https://media.roboflow.com/notebooks/examples/dog.jpeg\n",
            "Resolving media.roboflow.com (media.roboflow.com)... 34.110.133.209\n",
            "Connecting to media.roboflow.com (media.roboflow.com)|34.110.133.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 106055 (104K) [image/jpeg]\n",
            "Saving to: ‘dog.jpeg’\n",
            "\n",
            "\rdog.jpeg              0%[                    ]       0  --.-KB/s               \rdog.jpeg            100%[===================>] 103.57K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-08-24 16:15:36 (113 MB/s) - ‘dog.jpeg’ saved [106055/106055]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "run inference"
      ],
      "metadata": {
        "id": "wFZkeZL3t-RT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "\n",
        "\n",
        "image_path = f\"/content/dog.jpeg\"\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "model = YOLO('yolov12l.pt')\n",
        "\n",
        "results = model(image, verbose=False)[0]\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "\n",
        "sv.plot_image(annotated_image)"
      ],
      "metadata": {
        "id": "RBCygdpytHPM",
        "outputId": "9ae2cc98-4c38-49ee-cb53-948c6c3b8390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/yolov12/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "FlashAttention is not available on this device. Using scaled_dot_product_attention instead.\n",
            "Downloading https://github.com/sunsmarterjie/yolov12/releases/download/turbo/yolov12l.pt to 'yolov12l.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51.4M/51.4M [00:00<00:00, 209MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset from Roboflow"
      ],
      "metadata": {
        "id": "xjOTCa19uBRi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VCCLWK2EtaHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "ETZnRNX3ZCeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagehash"
      ],
      "metadata": {
        "id": "Ug1950mIa63U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import imagehash\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "Nz3NzFGdYRxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Colab Notebooks/AI ML/License Plate Recognition Data Set\"\n",
        "splits = [\"train\", \"valid\", \"test\"]"
      ],
      "metadata": {
        "id": "StbuaSWVYVmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------- 1. Validate annotation pairs -------------------\n",
        "# -----------------------------------------------------------\n",
        "# Helper: Plot before/after\n",
        "def plot_comparison(before_dict, after_dict, title, xlabel, ylabel):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12,5))\n",
        "\n",
        "    axs[0].bar(before_dict.keys(), before_dict.values(), color=\"skyblue\")\n",
        "    axs[0].set_title(f\"{title} (Before)\")\n",
        "    axs[0].set_xlabel(xlabel); axs[0].set_ylabel(ylabel)\n",
        "\n",
        "    axs[1].bar(after_dict.keys(), after_dict.values(), color=\"lightgreen\")\n",
        "    axs[1].set_title(f\"{title} (After)\")\n",
        "    axs[1].set_xlabel(xlabel); axs[1].set_ylabel(ylabel)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Validate Annotation Pairs\n",
        "for split in splits:\n",
        "    img_dir = Path(dataset_path) / split / \"images\"\n",
        "    lbl_dir = Path(dataset_path) / split / \"labels\"\n",
        "\n",
        "    img_files = {f.stem for f in img_dir.glob(\"*\")}\n",
        "    lbl_files = {f.stem for f in lbl_dir.glob(\"*\")}\n",
        "\n",
        "    before_stats = {\"images\": len(img_files), \"labels\": len(lbl_files)}\n",
        "\n",
        "    missing_labels = img_files - lbl_files\n",
        "    missing_images = lbl_files - img_files\n",
        "\n",
        "    for fname in missing_labels:\n",
        "        (img_dir / f\"{fname}.jpg\").unlink(missing_ok=True)\n",
        "        (img_dir / f\"{fname}.png\").unlink(missing_ok=True)\n",
        "    for fname in missing_images:\n",
        "        (lbl_dir / f\"{fname}.txt\").unlink(missing_ok=True)\n",
        "\n",
        "    img_files = {f.stem for f in img_dir.glob(\"*\")}\n",
        "    lbl_files = {f.stem for f in lbl_dir.glob(\"*\")}\n",
        "    after_stats = {\"images\": len(img_files), \"labels\": len(lbl_files)}\n",
        "\n",
        "    plot_comparison(before_stats, after_stats, f\"{split.upper()} - Image/Label Pairs\", \"Type\", \"Count\")\n"
      ],
      "metadata": {
        "id": "sGBKxJz-NkcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 2. Image Quality Filtering (delete image + its label)\n",
        "BLUR_THRESHOLD = 100\n",
        "CONTRAST_THRESHOLD = 15\n",
        "\n",
        "for split in splits:\n",
        "    img_dir = Path(dataset_path) / split / \"images\"\n",
        "    lbl_dir = Path(dataset_path) / split / \"labels\"\n",
        "\n",
        "    blur_scores = {}\n",
        "    contrast_scores = {}\n",
        "\n",
        "    for img_file in img_dir.glob(\"*\"):\n",
        "        img = cv2.imread(str(img_file), cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            continue\n",
        "        blur_val = cv2.Laplacian(img, cv2.CV_64F).var()\n",
        "        contrast_val = cv2.calcHist([img],[0],None,[256],[0,256]).std()\n",
        "        blur_scores[img_file] = blur_val\n",
        "        contrast_scores[img_file] = contrast_val\n",
        "\n",
        "    before_stats = {\"total_images\": len(blur_scores)}\n",
        "\n",
        "    for img_file, blur_val in blur_scores.items():\n",
        "        contrast_val = contrast_scores[img_file]\n",
        "\n",
        "        if blur_val < BLUR_THRESHOLD or contrast_val < CONTRAST_THRESHOLD:\n",
        "            img_file.unlink(missing_ok=True)\n",
        "\n",
        "            label_file = lbl_dir / (img_file.stem + \".txt\")\n",
        "            if label_file.exists():\n",
        "                label_file.unlink()\n",
        "\n",
        "    after_stats = {\"total_images\": len(list(img_dir.glob('*')))}\n",
        "\n",
        "    plot_comparison(before_stats, after_stats, f\"{split.upper()} - Image Quality Filter\", \"Category\", \"Count\")\n"
      ],
      "metadata": {
        "id": "99eQBitDYl9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 3. Check Image File Formats\n",
        "valid_exts = {\".jpg\", \".jpeg\", \".png\"}\n",
        "\n",
        "for split in splits:\n",
        "    img_dir = Path(dataset_path) / split / \"images\"\n",
        "\n",
        "    # Count before\n",
        "    before_stats = defaultdict(int)\n",
        "    for f in img_dir.glob(\"*\"):\n",
        "        before_stats[f.suffix.lower()] += 1\n",
        "\n",
        "    # Delete invalid files\n",
        "    for f in img_dir.glob(\"*\"):\n",
        "        if f.suffix.lower() not in valid_exts:\n",
        "            f.unlink()\n",
        "\n",
        "    # Count after\n",
        "    after_stats = defaultdict(int)\n",
        "    for f in img_dir.glob(\"*\"):\n",
        "        after_stats[f.suffix.lower()] += 1\n",
        "\n",
        "    plot_comparison(before_stats, after_stats, f\"{split.upper()} - File Format Check\", \"Extension\", \"Count\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LrdhmQMYYrR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 4. Duplicate Image Detection\n",
        "for split in splits:\n",
        "    img_dir = Path(dataset_path) / split / \"images\"\n",
        "\n",
        "    seen_hashes = {}\n",
        "    duplicates = []\n",
        "\n",
        "    before_count = len(list(img_dir.glob(\"*\")))\n",
        "\n",
        "    for img_file in img_dir.glob(\"*\"):\n",
        "        try:\n",
        "            img = Image.open(img_file)\n",
        "            h = imagehash.phash(img)\n",
        "        except:\n",
        "            continue\n",
        "        if h in seen_hashes:\n",
        "            duplicates.append(img_file)\n",
        "            img_file.unlink()\n",
        "        else:\n",
        "            seen_hashes[h] = img_file\n",
        "\n",
        "    after_count = len(list(img_dir.glob(\"*\")))\n",
        "\n",
        "    plot_comparison({\"images\": before_count}, {\"images\": after_count}, f\"{split.upper()} - Duplicate Removal\", \"Category\", \"Count\")"
      ],
      "metadata": {
        "id": "8qjhCb73YumI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/License-Plate-Recognition-11\"\n",
        "\n",
        "!sed -i '$d' {dataset_path}/data.yaml\n",
        "!sed -i '$d' {dataset_path}/data.yaml\n",
        "!sed -i '$d' {dataset_path}/data.yaml\n",
        "!sed -i '$d' {dataset_path}/data.yaml\n",
        "\n",
        "!echo -e \"test: ../test/images\\ntrain: ../train/images\\nval: ../valid/images\" >> {dataset_path}/data.yaml\n"
      ],
      "metadata": {
        "id": "kZTKu1T7tyEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat {dataset_path}/data.yaml"
      ],
      "metadata": {
        "id": "_xY05vp3ty97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tunning"
      ],
      "metadata": {
        "id": "oZg_YXsKuDoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov12s.yaml')\n",
        "\n",
        "results = model.train(data=f'{dataset_path}/data.yaml', epochs=100)"
      ],
      "metadata": {
        "id": "EWhFEpKDuGQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!ls {HOME}/runs/detect/train/"
      ],
      "metadata": {
        "id": "CG6Hd637zfbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=1000)"
      ],
      "metadata": {
        "id": "aaxw0RhFuOzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f'{HOME}/runs/detect/train/results.png', width=1000)"
      ],
      "metadata": {
        "id": "z-T58jZiuP8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "ds = sv.DetectionDataset.from_yolo(\n",
        "    images_directory_path=f\"{dataset_path}/test/images\",\n",
        "    annotations_directory_path=f\"{dataset_path}/test/labels\",\n",
        "    data_yaml_path=f\"{dataset_path}/data.yaml\"\n",
        ")\n",
        "\n",
        "ds.classes"
      ],
      "metadata": {
        "id": "jKHHpKIUuQxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.metrics import MeanAveragePrecision\n",
        "\n",
        "model = YOLO(f'/{HOME}/runs/detect/train/weights/best.pt')\n",
        "\n",
        "predictions = []\n",
        "targets = []\n",
        "\n",
        "for _, image, target in ds:\n",
        "    results = model(image, verbose=False)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "    predictions.append(detections)\n",
        "    targets.append(target)\n",
        "\n",
        "map = MeanAveragePrecision().update(predictions, targets).compute()"
      ],
      "metadata": {
        "id": "jRiicLChuRyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"mAP 50:95\", map.map50_95)\n",
        "print(\"mAP 50\", map.map50)\n",
        "print(\"mAP 75\", map.map75)"
      ],
      "metadata": {
        "id": "QG13z4CxuUlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map.plot()"
      ],
      "metadata": {
        "id": "L_nK8ed1uWiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision\n",
        "\n",
        "import supervision as sv\n",
        "\n",
        "model = YOLO(f'/{HOME}/runs/detect/train/weights/best.pt')\n",
        "\n",
        "ds = sv.DetectionDataset.from_yolo(\n",
        "    images_directory_path=f\"{dataset_path}/test/images\",\n",
        "    annotations_directory_path=f\"{dataset_path}/test/labels\",\n",
        "    data_yaml_path=f\"{dataset_path}/data.yaml\"\n",
        ")"
      ],
      "metadata": {
        "id": "7RaDryqwueT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "i = random.randint(0, len(ds))\n",
        "\n",
        "image_path, image, target = ds[i]\n",
        "\n",
        "results = model(image, verbose=False)[0]\n",
        "detections = sv.Detections.from_ultralytics(results).with_nms()\n",
        "\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "\n",
        "sv.plot_image(annotated_image)"
      ],
      "metadata": {
        "id": "FPUtL-HZufJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for _, image, target in ds:\n",
        "    results = model(image, verbose=False)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "    for lbl in target[\"class_id\"]:\n",
        "        y_true.append(lbl)\n",
        "\n",
        "    for lbl in detections.class_id:\n",
        "        y_pred.append(lbl)\n",
        "\n",
        "min_len = min(len(y_true), len(y_pred))\n",
        "y_true = y_true[:min_len]\n",
        "y_pred = y_pred[:min_len]\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "print(\"Prediction Accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "5geGXk7VI0mJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}