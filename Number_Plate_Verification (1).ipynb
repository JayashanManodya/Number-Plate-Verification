{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "XdyV9svaXez6",
        "outputId": "0519b095-4853-4e58-f2d9-17e5b94a81ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dependencies"
      ],
      "metadata": {
        "id": "HJJbpJ4bt4io"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBBV2HPcr1y3"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/sunsmarterjie/yolov12.git roboflow supervision flash-attn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "example data"
      ],
      "metadata": {
        "id": "muM1Aivct8ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://media.roboflow.com/notebooks/examples/dog.jpeg"
      ],
      "metadata": {
        "id": "ZmLG4N2Jsswc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "run inference"
      ],
      "metadata": {
        "id": "wFZkeZL3t-RT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "\n",
        "\n",
        "image_path = f\"/content/dog.jpeg\"\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "model = YOLO('yolov12l.pt')\n",
        "\n",
        "results = model(image, verbose=False)[0]\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "\n",
        "sv.plot_image(annotated_image)"
      ],
      "metadata": {
        "id": "RBCygdpytHPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset from Roboflow"
      ],
      "metadata": {
        "id": "xjOTCa19uBRi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VCCLWK2EtaHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "ETZnRNX3ZCeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagehash"
      ],
      "metadata": {
        "id": "Ug1950mIa63U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import imagehash\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "Nz3NzFGdYRxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Colab Notebooks/AI ML/License Plate Recognition Data Set\"\n",
        "splits = [\"train\", \"valid\", \"test\"]"
      ],
      "metadata": {
        "id": "StbuaSWVYVmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------- 1. Validate annotation pairs -------------------\n",
        "# -----------------------------------------------------------\n",
        "# Helper: Plot before/after\n",
        "def plot_comparison(before_dict, after_dict, title, xlabel, ylabel):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12,5))\n",
        "\n",
        "    axs[0].bar(before_dict.keys(), before_dict.values(), color=\"skyblue\")\n",
        "    axs[0].set_title(f\"{title} (Before)\")\n",
        "    axs[0].set_xlabel(xlabel); axs[0].set_ylabel(ylabel)\n",
        "\n",
        "    axs[1].bar(after_dict.keys(), after_dict.values(), color=\"lightgreen\")\n",
        "    axs[1].set_title(f\"{title} (After)\")\n",
        "    axs[1].set_xlabel(xlabel); axs[1].set_ylabel(ylabel)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Validate Annotation Pairs\n",
        "for split in splits:\n",
        "    img_dir = Path(dataset_path) / split / \"images\"\n",
        "    lbl_dir = Path(dataset_path) / split / \"labels\"\n",
        "\n",
        "    img_files = {f.stem for f in img_dir.glob(\"*\")}\n",
        "    lbl_files = {f.stem for f in lbl_dir.glob(\"*\")}\n",
        "\n",
        "    before_stats = {\"images\": len(img_files), \"labels\": len(lbl_files)}\n",
        "\n",
        "    missing_labels = img_files - lbl_files\n",
        "    missing_images = lbl_files - img_files\n",
        "\n",
        "    for fname in missing_labels:\n",
        "        (img_dir / f\"{fname}.jpg\").unlink(missing_ok=True)\n",
        "        (img_dir / f\"{fname}.png\").unlink(missing_ok=True)\n",
        "    for fname in missing_images:\n",
        "        (lbl_dir / f\"{fname}.txt\").unlink(missing_ok=True)\n",
        "\n",
        "    img_files = {f.stem for f in img_dir.glob(\"*\")}\n",
        "    lbl_files = {f.stem for f in lbl_dir.glob(\"*\")}\n",
        "    after_stats = {\"images\": len(img_files), \"labels\": len(lbl_files)}\n",
        "\n",
        "    plot_comparison(before_stats, after_stats, f\"{split.upper()} - Image/Label Pairs\", \"Type\", \"Count\")\n"
      ],
      "metadata": {
        "id": "sGBKxJz-NkcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 2. Image Quality Filtering (delete image + its label)\n",
        "BLUR_THRESHOLD = 100\n",
        "CONTRAST_THRESHOLD = 15\n",
        "\n",
        "for split in splits:\n",
        "    img_dir = Path(dataset_path) / split / \"images\"\n",
        "    lbl_dir = Path(dataset_path) / split / \"labels\"\n",
        "\n",
        "    blur_scores = {}\n",
        "    contrast_scores = {}\n",
        "\n",
        "    for img_file in img_dir.glob(\"*\"):\n",
        "        img = cv2.imread(str(img_file), cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            continue\n",
        "        blur_val = cv2.Laplacian(img, cv2.CV_64F).var()\n",
        "        contrast_val = cv2.calcHist([img],[0],None,[256],[0,256]).std()\n",
        "        blur_scores[img_file] = blur_val\n",
        "        contrast_scores[img_file] = contrast_val\n",
        "\n",
        "    before_stats = {\"total_images\": len(blur_scores)}\n",
        "\n",
        "    for img_file, blur_val in blur_scores.items():\n",
        "        contrast_val = contrast_scores[img_file]\n",
        "\n",
        "        if blur_val < BLUR_THRESHOLD or contrast_val < CONTRAST_THRESHOLD:\n",
        "            img_file.unlink(missing_ok=True)\n",
        "\n",
        "            label_file = lbl_dir / (img_file.stem + \".txt\")\n",
        "            if label_file.exists():\n",
        "                label_file.unlink()\n",
        "\n",
        "    after_stats = {\"total_images\": len(list(img_dir.glob('*')))}\n",
        "\n",
        "    plot_comparison(before_stats, after_stats, f\"{split.upper()} - Image Quality Filter\", \"Category\", \"Count\")\n"
      ],
      "metadata": {
        "id": "99eQBitDYl9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 3. Check Image File Formats\n",
        "valid_exts = {\".jpg\", \".jpeg\", \".png\"}\n",
        "\n",
        "for split in splits:\n",
        "    img_dir = Path(dataset_path) / split / \"images\"\n",
        "\n",
        "    # Count before\n",
        "    before_stats = defaultdict(int)\n",
        "    for f in img_dir.glob(\"*\"):\n",
        "        before_stats[f.suffix.lower()] += 1\n",
        "\n",
        "    # Delete invalid files\n",
        "    for f in img_dir.glob(\"*\"):\n",
        "        if f.suffix.lower() not in valid_exts:\n",
        "            f.unlink()\n",
        "\n",
        "    # Count after\n",
        "    after_stats = defaultdict(int)\n",
        "    for f in img_dir.glob(\"*\"):\n",
        "        after_stats[f.suffix.lower()] += 1\n",
        "\n",
        "    plot_comparison(before_stats, after_stats, f\"{split.upper()} - File Format Check\", \"Extension\", \"Count\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LrdhmQMYYrR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------\n",
        "# 4. Duplicate Image Detection\n",
        "for split in splits:\n",
        "    img_dir = Path(dataset_path) / split / \"images\"\n",
        "\n",
        "    seen_hashes = {}\n",
        "    duplicates = []\n",
        "\n",
        "    before_count = len(list(img_dir.glob(\"*\")))\n",
        "\n",
        "    for img_file in img_dir.glob(\"*\"):\n",
        "        try:\n",
        "            img = Image.open(img_file)\n",
        "            h = imagehash.phash(img)\n",
        "        except:\n",
        "            continue\n",
        "        if h in seen_hashes:\n",
        "            duplicates.append(img_file)\n",
        "            img_file.unlink()\n",
        "        else:\n",
        "            seen_hashes[h] = img_file\n",
        "\n",
        "    after_count = len(list(img_dir.glob(\"*\")))\n",
        "\n",
        "    plot_comparison({\"images\": before_count}, {\"images\": after_count}, f\"{split.upper()} - Duplicate Removal\", \"Category\", \"Count\")"
      ],
      "metadata": {
        "id": "8qjhCb73YumI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/License-Plate-Recognition-11\"\n",
        "\n",
        "!sed -i '$d' {dataset_path}/data.yaml\n",
        "!sed -i '$d' {dataset_path}/data.yaml\n",
        "!sed -i '$d' {dataset_path}/data.yaml\n",
        "!sed -i '$d' {dataset_path}/data.yaml\n",
        "\n",
        "!echo -e \"test: ../test/images\\ntrain: ../train/images\\nval: ../valid/images\" >> {dataset_path}/data.yaml\n",
        "!cat {dataset_path}/data.yaml\n"
      ],
      "metadata": {
        "id": "kZTKu1T7tyEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat {dataset_path}/data.yaml"
      ],
      "metadata": {
        "id": "_xY05vp3ty97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tunning"
      ],
      "metadata": {
        "id": "oZg_YXsKuDoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov12s.yaml')\n",
        "\n",
        "results = model.train(data=f'{dataset_path}/data.yaml', epochs=100)"
      ],
      "metadata": {
        "id": "EWhFEpKDuGQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=1000)"
      ],
      "metadata": {
        "id": "aaxw0RhFuOzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f'{HOME}/runs/detect/train/results.png', width=1000)"
      ],
      "metadata": {
        "id": "z-T58jZiuP8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "ds = sv.DetectionDataset.from_yolo(\n",
        "    images_directory_path=f\"{dataset_path}/test/images\",\n",
        "    annotations_directory_path=f\"{dataset_path}/test/labels\",\n",
        "    data_yaml_path=f\"{dataset_path}/data.yaml\"\n",
        ")\n",
        "\n",
        "ds.classes"
      ],
      "metadata": {
        "id": "jKHHpKIUuQxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.metrics import MeanAveragePrecision\n",
        "\n",
        "model = YOLO(f'/{HOME}/runs/detect/train/weights/best.pt')\n",
        "\n",
        "predictions = []\n",
        "targets = []\n",
        "\n",
        "for _, image, target in ds:\n",
        "    results = model(image, verbose=False)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "    predictions.append(detections)\n",
        "    targets.append(target)\n",
        "\n",
        "map = MeanAveragePrecision().update(predictions, targets).compute()"
      ],
      "metadata": {
        "id": "jRiicLChuRyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"mAP 50:95\", map.map50_95)\n",
        "print(\"mAP 50\", map.map50)\n",
        "print(\"mAP 75\", map.map75)"
      ],
      "metadata": {
        "id": "QG13z4CxuUlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map.plot()"
      ],
      "metadata": {
        "id": "L_nK8ed1uWiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision\n",
        "\n",
        "import supervision as sv\n",
        "\n",
        "model = YOLO(f'/{HOME}/runs/detect/train/weights/best.pt')\n",
        "\n",
        "ds = sv.DetectionDataset.from_yolo(\n",
        "    images_directory_path=f\"{dataset_path}/test/images\",\n",
        "    annotations_directory_path=f\"{dataset_path}/test/labels\",\n",
        "    data_yaml_path=f\"{dataset_path}/data.yaml\"\n",
        ")"
      ],
      "metadata": {
        "id": "7RaDryqwueT1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "outputId": "87174e3f-d25c-493d-a007-f4ac37023594"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supervision\n",
            "  Downloading supervision-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from supervision) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (1.16.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (6.0.2)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.12/dist-packages (from supervision) (11.3.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (4.67.1)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.12/dist-packages (from supervision) (4.12.0.88)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.17.0)\n",
            "Downloading supervision-0.26.1-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: supervision\n",
            "Successfully installed supervision-0.26.1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'YOLO' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2906994765.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msupervision\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/{HOME}/runs/detect/train/weights/best.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ds = sv.DetectionDataset.from_yolo(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'YOLO' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "i = random.randint(0, len(ds))\n",
        "\n",
        "image_path, image, target = ds[i]\n",
        "\n",
        "results = model(image, verbose=False)[0]\n",
        "detections = sv.Detections.from_ultralytics(results).with_nms()\n",
        "\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
        "\n",
        "sv.plot_image(annotated_image)"
      ],
      "metadata": {
        "id": "FPUtL-HZufJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for _, image, target in ds:\n",
        "    results = model(image, verbose=False)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "    for lbl in target[\"class_id\"]:\n",
        "        y_true.append(lbl)\n",
        "\n",
        "    for lbl in detections.class_id:\n",
        "        y_pred.append(lbl)\n",
        "\n",
        "min_len = min(len(y_true), len(y_pred))\n",
        "y_true = y_true[:min_len]\n",
        "y_pred = y_pred[:min_len]\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "print(\"Prediction Accuracy:\", acc)\n"
      ],
      "metadata": {
        "id": "5geGXk7VI0mJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}